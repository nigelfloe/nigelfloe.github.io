---
layout: post
title: "More than one way to shear an Electric Sheep"
date: 2015-09-20 17:27:20 -0400
comments: true
categories: "Flatiron&nbsp;School"
---
## Android Dreams v1
One of my favorite apps is [Electric Sheep](http://electricsheep.org/), an open source "collaborative abstract artwork" masquerading as a flashy screensaver. While your computer is sleeping, it uses creator Scott Draves [flame algorithm](http://scottdraves.com/flame.html) to render animations affectionately referred to as ["sheep"](http://imgur.com/gallery/RcsjPpd).

Sheep are initially created and uploaded to the program's "gene pool" by community members. All sleeping computers running Electric Sheep act as a distributed network, sharing the sheep and mutating them algorithmically. As time goes on the current ["flock"](http://v2d7c.sheepserver.net/cgi/best.cgi) will slowly change form and "evolve". This process is directed by users of the program, who can up or down vote the sheep as they run, providing a proxy for natural selection, as the less popular sheep make their way out of the gene pool, and any given sheep's designer or ["family tree"](http://v2d7c.sheepserver.net/cgi/node.cgi?id=5352&detail=lineage) can be viewed on the program's website.

![electricsheep.org](http://v2d7c.sheepserver.net/gen/245/3422/electricsheep.245.03422.jpg)

---
### Sidebar:
Draves's Flame algorithm was created in 1991 and is often sited as the first use of the GPL open source license for art and graphics applications, and Flame algorithms have shown up [all over the place](https://www.youtube.com/watch?v=GdIjCSi1XOk).

---

## Enter Google
Electric Sheep's visualizations bear a more than passing similarity to a [Twitch livestream](http://www.twitch.tv/317070) of the "hallucinations" of an AI programmed by a group of PhD students at Belgium's Ghent University. Their AI is built on [research recently published by Google](http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html) into deep neural networks which were originally built to identify and classify images based on their content. Google's researchers found that these networks, once primed with the keyword of an object they could recognize, were also primed with the information necessary to *generate* images, with some pretty surreal results:

![http://bit.ly/1Fo28lX](https://lh3.googleusercontent.com/SrqGJTXPiuw0f3VrLtpciJd2vIG34nSKkzyRGEWh5g8XDQ3TSxlCtyCbASXHYQR4IqzTBD4-4ChRFJ-ODU7vu-MTMzU9M5kT7RobDP6WP0PFCtTBY5SXyEcmYzSiBxSkO28oheMrQWLdIJ95qxFrNJRqwaXouKDqE0iVLdMg4rlzpsAjD9zIaaUQ_gVNU20mxqrtcTjvXKEoZdd_SmbqmY-_Pp3KP_mWgnyL0CQdlv8UqN-5Lpoh1Gchz9RUns-nVaM1Zbiyq_XyY6ylTu8AAE0flUl8K5CR5wAdNSfak8P1P0dcAROGubEFOVRJqjNKKQRuM71v1gCakFtsEflg1sPv2GuZM4oDAP-OTtTY4B7S6kjGpSowsv3GhXB_ZRbKbw-xGoSRbd7_-0gACc4tTcUH0JeuQF0OdQAlKMuVe5Nwu0OwKVsfT90dt3F7JtxKdd0YYiR1i3MV6e-pqRqJNnqOZfGQfAO-rj6Gp-h0Osvye32r1tq38_VIJs9hfYoAAw9VhLBaSIzGw05d3wS7kQJBlcNxYBiCictI39TPnBw=w716-h448-no)

![http://bit.ly/1Fo28lX](https://lh3.googleusercontent.com/wXxsgrvrYmxa7ad4ro7dekU2yZw4CKtRnWwA7E_5hZqLD5_L2b7PIlp6j7MKbstGjDHgtpkKiIXgfwLQetDI16ciF7IKWmIzTipY5c5m3aGtySQsAg5-rks904BzkMgeCUtW7-x5SWXcrK13YwCU9reJWALOa7bC4xUFj2ovtJDYGTOwrcNE3dwbMTZzWMcbeOmjojb2-epO4hhemZn5Hql8nrwx8TeAcwjZkaGdqUZX3Cg4vxw1-KSkn8HGv_HWEG1VWtX_CfVrYkDbX0PpKhBkVgFtWIYM5JJiVNvpN-aRNoZzKIKxeY0D45TmO2kTc1jAZdOhUnmb7SWxd3zbryI5aWV_BjNqk2JXIiOAtWn1XDJwKLwUZ3cvPqLYzjOCe_xIw1G6vJbyA2X-n7jVDVhWKqLlHJ7Q5dRhwX305T1WetEr8p7odpCmKq3o3RE7hJu9_3tr6XHvms5gNi2PEvkTFu__s7AZwr01xT8RxNOkpd05RiLiYmPLUaUVrLKc_jlPmxY0GUKfqAFWm8vbb0KAymIKjKHKIxA5b6o6kEY=w1200-h800-no)

![http://bit.ly/1Fo28lX](https://lh3.googleusercontent.com/k4Re_tnPfAHlfpu9XgyXFLhgLEpi4IrfPpk2J9y3AaMbUeaEwzXHeJtUoOOUA0quIexkOs65lQ_5VhyDRSbzvJKyNLOfSnzNT2Rl2p2nqH_1Tf2GaxirNTaCwb58Z5rNep3mN2wIJ0Dz3VDJ1uiER68d2xSBfxrP6h1ZjjDCt_pdRqBwHkAiRnjf13cz43bwR8JYUAfvwcGqqKjLGT-X6ItYgDqJbYA09GtI21ZYFd8_hcI-HMy4Xcp-OszMOEnjD19ukMhyXaK55b0GR32hsPUAc2i_j4vthAfo0MUoMRkzrB9JCDYuLn4Gv_68dlAQn595IFp0wOclq8CmMUFE8Uh9sJwC5YqMvNn_1VSId5gcL-mKEgJ-THNMOItqEvxhPRma4Ym3putVfGJn9G_YvGUJ46kiHFOQ7RyWraVfJ6QeLfCwHb5OUX9mTqPJT8rpkMv3uULydDX5yRmN1H5WYDEicqMmRIgv2yvHZHx3sQCFAY3TXMWgSmHqJDxsZ0cKA7TjdI2MFtgRZVhZM80o6rReKKdx3TovAGd-KOHQi-o=w1180-h862-no)

The Guardian printed solid articles both [Google's initial research](http://www.theguardian.com/technology/2015/jun/18/google-image-recognition-neural-network-androids-dream-electric-sheep) and [the Belgian livestream](http://www.theguardian.com/technology/2015/jun/25/watch-android-dream-electric-sheep-live), so check out those articles if you are interested, as well. The above images are sourced from the [photo blog](https://photos.google.com/share/AF1QipPX0SCl7OzWilt9LnuQliattX4OUCj_8EP65_cTVnBmS1jnYgsGQAieQUc1VQWdgQ?key=aVBxWjhwSzg2RjJWLWRuVFBBZEN1d205bUdEMnhB) of Michael Tyka, and there are many more images there.

## A Super Basic Intro to Neural Networks
Apart from creating self-evolving animations, classifying images, or generating android dreams, neural networks have many applications, from use in hearing aids and cochlear implants, to self-driving cars, to facial recognition software and robotics.

But [what is a neural network?](https://vimeo.com/62218296)

![](http://images3.wikia.nocookie.net/__cb20080524190504/uncyclopedia/images/7/79/What_are_birds.jpg)

Let's start with a definition:

### "[An artificial neural network is] a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs."
#### - In "Neural Network Primer: Part I" by Maureen Caudill, AI Expert, Feb. 1989

....ok, maybe that helped a little.

Artificial neural networks, which we are discussing here, are modeled after the networks of neurons found in animal brains and nervous systems.

![source: https://blogs.cornell.edu/info2040/2015/09/08/neural-networks-and-machine-learning/](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvPd9clSfYmmekdGvkfkjzleYP0tllyW7aH-JfoBC4hhmMVuEp)
In this model, each processing element can be thought of as a neuron in the brain, which at a basic level:

1. receives some positive number of inputs from an external source
2. processes these inputs based on remembered or programmed behavior
3. sends an output to another neuron or neurons in the network

![source: http://natureofcode.com/book/chapter-10-neural-networks/](http://natureofcode.com/book/imgs/chapter10/ch10_03.png)

In the above diagram, we can see a model of the simplest neural network possible, a perceptron. This perceptron receives 2 inputs, processes them, and sends an output out along the line.

The following example is taken from [Chapter 10 of Daniel Shiffman's *The Nature of Code*](http://natureofcode.com/book/chapter-10-neural-networks/):

---
**Step 1: Receive inputs.**

Say we have a perceptron with two inputs—let’s call them x1 and x2.

_Input 0: x1 = 12_
_Input 1: x2 = 4_

**Step 2: Weight inputs.**

Each input that is sent into the neuron must first be weighted, i.e. multiplied by some value (often a number between -1 and 1). When creating a perceptron, we’ll typically begin by assigning random weights. Here, let’s give the inputs the following weights:

_Weight 0: 0.5_
_Weight 1: -1_

We take each input and multiply it by its weight.

_Input 0 * Weight 0 ⇒ 12 * 0.5 = 6_

_Input 1 * Weight 1 ⇒ 4 * -1 = -4_

**Step 3: Sum inputs.**

The weighted inputs are then summed.

_Sum = 6 + -4 = 2_

**Step 4: Generate output.**

The output of a perceptron is generated by passing that sum through an activation function. In the case of a simple binary output, the activation function is what tells the perceptron whether to “fire” or not. You can envision an LED connected to the output signal: if it fires, the light goes on; if not, it stays off.

Activation functions can get a little bit hairy. If you start reading one of those artificial intelligence textbooks looking for more info about activation functions, you may soon find yourself reaching for a calculus textbook. However, with our friend the simple perceptron, we’re going to do something really easy. Let’s make the activation function the sign of the sum. In other words, if the sum is a positive number, the output is 1; if it is negative, the output is -1.

_Output = sign(sum) ⇒ sign(2) ⇒ +1_

Let’s review and condense these steps so we can implement them with a code snippet.

**The Perceptron Algorithm:**

* For every input, multiply that input by its weight.

* Sum all of the weighted inputs.

* Compute the output of the perceptron based on that sum passed through an activation function (the sign of the sum).

---

This is the basic process of each unit in a neural network. Once the network has provided its final output, the outcome will be used to adjust the weights of the network's inputs. Of course, in a real world application, a neural network would consist of many, many nodes like our perceptron, each of them dynamically responding and reweighing its inputs based on output from its neighbors, and the problem being solved would be much more complicated than determining if a sum is positive or negative.

The image below shows a simple multi-node neural network. This example is 3-layer network, and you can see that the potential behavior is already much more complicated:

![source: Wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/560px-Artificial_neural_network.svg.png)

The central layer is labeled "hidden" because the user of such a network does not have direct access to the network's behavior in the middle layer; we can only directly observe what external inputs precipitated a given output. For this reason, the inner-workings of complex neural networks, such as those behind Google's image classifier or self-driving cars remain somewhat mysterious, as it is possible to have a working network without understanding precisely why the program works.

Among other secrets, these hidden neural layers house the stuff of robotic dreams.

![](https://media.giphy.com/media/mAeS8x4HQdhMA/giphy.gif)
